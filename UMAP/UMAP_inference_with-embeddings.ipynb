{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e3638a-ff3f-479e-80e5-b7b18bae5a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from ..balm.config import BalmConfig, BalmMoEConfig\n",
    "from ..balm.data import load_dataset, DataCollator\n",
    "from ..balm.models import (\n",
    "    BalmForMaskedLM,\n",
    "    BalmModel,\n",
    "    BalmMoEForMaskedLM,\n",
    ")\n",
    "from ..balm.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9f11b-012f-4370-b557-dcd7f3358938",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a4510ef-b4d7-42c5-873a-005877770a4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BalmMoEForMaskedLM.from_pretrained(\"../training_runs/balmMoE_expertchoice_1shared_altern_052924/model\")\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9eb5bb-d303-449b-8dd3-ce7646da8f93",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132c633a-f7df-4c1b-84de-771f506f9e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"../balm/vocab.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1dd31-b174-4366-ba39-cd93ae84a783",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "891283f0-6c83-4f42-a7e2-685cacdd3e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " df = pd.read_csv('./lc-coherence_test-unique_annotated.csv')\n",
    "df['chain'] = ['heavy' if l == 'IGH' else 'light' for l in df['locus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c0db03-c495-4089-ad6e-1fb4936d47b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_df = df.pivot(\n",
    "    index='pair_id', \n",
    "    columns='chain',\n",
    "    values='sequence_aa'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85ffbfe-031f-401d-bc48-ac3f19028908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs = []\n",
    "for h, l in zip(seq_df['heavy'], seq_df['light']):\n",
    "    seqs.append(\"{}<cls><cls>{}\".format(h, l))\n",
    "    \n",
    "seq_names = list(seq_df.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93ce3683-ecb0-4c8b-b4bb-7fd4f75b0cae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EVQLWESGGGLVQPGGSLRLSCAASGFIFSSYAMIWVRQAPGKGLEWVSGISSSGGSTYYADSVKGRFTISRDNSKNTVYLQMNSLRTEDTAVYYCAKTNGAGSGKGYYYYGMDVWGQGTTVTVSS<cls><cls>EIVLTQSPGTLSLSPGESATLSCRASQSVSSTYLVWYQQKPGQAPRLLIYGASSRATGIPDRFSGSGSGTDFTLTISRLEPEDFAVYYCQQYGPSPLYTFGQGTKLEIR'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97393058-e131-4df3-b4a2-2eb5e435ee66",
   "metadata": {},
   "source": [
    "## tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f096b151-e5b2-4180-9d70-261be83577d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893a827049244d799eddecf676a1d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = []\n",
    "for s in tqdm(seqs):\n",
    "    tokenized_data.append(tokenizer(s, return_tensors='pt', padding=True, truncation=True, max_length=320)['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a2cfc-6817-4fc3-a12c-a9e16b16460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = {'input_ids': [t['input_ids'][0] for t in tokenized_data],\n",
    "     'attention_mask': [t['attention_mask'] for t in tokenized_data]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e815387-12a9-422e-9093-cf4247734e0d",
   "metadata": {},
   "source": [
    "## inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a939282-07da-4a88-b0fc-4028d683e454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelOutput:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    name: str\n",
    "    chain: str\n",
    "    mean_final_layer_embedding: np.ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6a43688-8361-4636-86a3-5208c119cc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d53856eb-6240-42a0-a435-aee1dea88fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f507130ef64e8e8a3c7d6e6170adab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1871/2462415349.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(i).unsqueeze(0).to('cuda'),\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "batch = 0\n",
    "batchsize = 20000\n",
    "\n",
    "x = slice(batch*batchsize, (batch+1)*batchsize)\n",
    "inputs = list(zip(seq_names[x], seqs[x], tokenized_data[x]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for name, seq, i in tqdm(inputs):\n",
    "        o = model(\n",
    "            torch.tensor(i).unsqueeze(0).to('cuda'),\n",
    "            output_hidden_states=True,\n",
    "            return_dict=False,\n",
    "        )\n",
    "        final_layer_hidden_state = np.array(o[1][6][0].to('cpu'))\n",
    "        h, l = seq.split('<cls><cls>')\n",
    "        h_state = final_layer_hidden_state[:len(h)]\n",
    "        l_state = final_layer_hidden_state[-len(l):]\n",
    "        outputs.append(ModelOutput(name, 'heavy', h_state.mean(axis=0)))\n",
    "        outputs.append(ModelOutput(name, 'light', l_state.mean(axis=0)))\n",
    "\n",
    "with open('./balmMoE_outputs_20k.pkl', 'wb') as f:\n",
    "    pickle.dump(outputs, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
