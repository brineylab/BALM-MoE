{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13975af6-d64d-4e60-b405-d2e97add53fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import abutils\n",
    "import abstar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a29e52-6805-4894-84fc-8f3d0e8be12b",
   "metadata": {},
   "source": [
    "Import and Align SARS-CoV2 mAbs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df50bf6-8df0-467b-9c3a-c9a0dabeb29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../TXG-20220218.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75943bc-369a-4a25-bdea-b823bf3665b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txg_df = df[df[\"Identifier\"].str.startswith(\"TXG\")]\n",
    "heavies = [abutils.Sequence(s, id=i) for s, i in zip(txg_df[\"vj_seq1\"], txg_df[\"Identifier\"])]\n",
    "lights = [abutils.Sequence(s, id=i) for s, i in zip(txg_df[\"vj_seq2\"], txg_df[\"Identifier\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cef150-bf46-4860-b777-1142b96d95ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running abstar...\n",
      "(1/1) ||||||||||||||||||||||||||||||||||||||||||||||||||||  100%\n",
      "\n",
      "478 sequences contained an identifiable rearrangement\n",
      "abstar completed in 10.88 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seqs = abstar.run(heavies + lights, output_type=\"airr\")\n",
    "pairs = abutils.core.pair.assign_pairs(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eab0ddd-1521-4ec2-ba1e-58601c0d9961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counterh = Counter([p.heavy[\"sequence_aa\"] for p in pairs])\n",
    "counterl = Counter([p.light[\"sequence_aa\"] for p in pairs])\n",
    "\n",
    "seq_aa_l = []\n",
    "germ_aa_l = []\n",
    "\n",
    "h_alignments = []\n",
    "l_alignments = []\n",
    "\n",
    "for p in pairs:\n",
    "    hgerm_aa = abutils.tl.translate(p.heavy[\"germline_alignment\"])\n",
    "    hseq_aa = abutils.tl.translate(p.heavy[\"sequence_alignment\"])\n",
    "    \n",
    "    lgerm_aa = abutils.tl.translate(p.light[\"germline_alignment\"])\n",
    "    lseq_aa = abutils.tl.translate(p.light[\"sequence_alignment\"])\n",
    "    \n",
    "    germ_aa = f'{hgerm_aa}<cls><cls>{lgerm_aa}'\n",
    "    germ_aa_l.append(germ_aa)\n",
    "    \n",
    "    seq_aa = f'{hseq_aa}<cls><cls>{lseq_aa}'\n",
    "    if seq_aa not in seq_aa_l:\n",
    "        haln = abutils.tl.global_alignment(hseq_aa, hgerm_aa, gap_open=25)\n",
    "        h_alignments.append(haln)\n",
    "        \n",
    "        laln = abutils.tl.global_alignment(lseq_aa, lgerm_aa, gap_open=25)\n",
    "        l_alignments.append(laln)\n",
    "        seq_aa_l.append(seq_aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e7100d-a5fa-4482-bdba-87a51a868d60",
   "metadata": {},
   "source": [
    "Retrieve Scores from Balm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "688eeb4d-1c4e-40c6-b240-c5e615212690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "from ..balm.config import BalmConfig, BalmMoEConfig\n",
    "from ..balm.data import load_dataset, DataCollator\n",
    "from ..balm.models import (\n",
    "    BalmForMaskedLM,\n",
    "    BalmModel,\n",
    "    BalmMoEForMaskedLM,\n",
    ")\n",
    "from ..balm.tokenizer import Tokenizer\n",
    "\n",
    "from Bio import SeqIO\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feaaeedc-bf1e-41ff-8f5a-7b46d543eadf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing BalmMoEForMaskedLM.\n",
      "\n",
      "All the weights of BalmMoEForMaskedLM were initialized from the model checkpoint at /home/jovyan/shared/simone/BALM_development_51324/training_runs/balmMoE_expertchoiceBig_1shared_altern_052924/balmMoE_expertchoiceBig_1shared_altern_052924/model/model.pt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BalmMoEForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = BalmMoEForMaskedLM.from_pretrained(\n",
    "    \"../training_runs/balmMoE_expertchoiceBig_1shared_altern_052924/model/\"\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22ea41d-62e7-4f3c-91bb-0839dceed83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seqs = germ_aa_l\n",
    "seqs = [s.replace('*', '.') for s in seqs]\n",
    "seq_names = [p.heavy.annotations['sequence_id'] for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9964dc89-910b-4c7c-9936-ff659f3d0f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab=\"../balm/vocab.json\")\n",
    "vocab = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5181ca15-428d-4a4d-b53f-55e986d09441",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4ce04f461a4c4796374f1985ebaa04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/239 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "masked_seqs = []\n",
    "masked_seqs_tok = []\n",
    "masked_seq_ids = []\n",
    "for s in tqdm(range(len(seqs))):\n",
    "    seq = seqs[s]\n",
    "    seq_id = seq_names[s]\n",
    "    for aa in range(len(seq)):\n",
    "        if (seq[aa] == '<') or (seq[aa] == '>') or (seq[aa] == 'c') or (seq[aa] == 'l') or (seq[aa] == 's'):\n",
    "            continue\n",
    "        else:\n",
    "            masked_seq = seq[:aa] + '<mask>' + seq[aa:]\n",
    "            masked_seqs.append(masked_seq)\n",
    "            masked_seqs_tok.append(tokenizer(masked_seq, return_tensors='pt', max_length = 320, padding = 'max_length')['input_ids'][0].to('cuda'))\n",
    "            masked_seq_ids.append(seq_id)\n",
    "    \n",
    "# finalize inputs\n",
    "inputs = list(zip(masked_seq_ids, masked_seqs, masked_seqs_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ada3db2-0f4c-44a2-899d-d8786b843aea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5d070e8401475ba5458ef0beca5b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = {}\n",
    "with torch.no_grad():\n",
    "    for name, seq, tokens in tqdm(inputs):\n",
    "        o = model(tokens.unsqueeze(0), output_hidden_states=True, return_dict=True)\n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        logits = softmax(o[\"logits\"]).to(device=\"cpu\").numpy()[0] #probabilities\n",
    "        mask_pos = seq.index(\"<mask>\")\n",
    "        name2 = f'{name}_pos{mask_pos}'\n",
    "        output[name2] = logits[mask_pos+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bd37099-f2dc-402f-829d-a79ec340fe9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame.from_dict(output)\n",
    "output_df.to_csv(\"./TXG_mAbs_maskedprobs_BALMMoE.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2138b-8fd0-4198-bb8e-693d0767036e",
   "metadata": {},
   "source": [
    "Compare Mutation Predictions to Germline Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da23302c-3773-4063-ace6-2af4d9d8058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import balmMoE scores\n",
    "output_df1 = pd.read_csv(\"./TXG_mAbs_maskedprobs_BALMMoE.csv\")\n",
    "output_df1.index = output_df1.iloc[:, 0]\n",
    "output_df1 = output_df1.iloc[:, 1:]\n",
    "output_df1.index = list(vocab.keys())\n",
    "output_df1= output_df1.T\n",
    "max_prob_aas = output_df1.idxmax(axis=1)\n",
    "output_df1[\"max_prob_aas\"] = max_prob_aas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef7aeda5-c578-4eac-a548-311d1fe968da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and prep sequences\n",
    "for s in range(len(seqs)):\n",
    "    seqs[s] = re.sub(r'<cls><cls>', '_________', seqs[s])\n",
    "    seqs[s] = re.sub(r'-', '_', seqs[s])\n",
    "    seqs[s] = re.sub(r'\\*', '.', seqs[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f0b0401-fbf8-4277-804d-13971b8aa2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d1bb1e0dd4404c94bdfc2630f90787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wt_dict = {}\n",
    "wt_prob_d = {}\n",
    "for row in tqdm(output_df1.index):\n",
    "    for i, s in list(zip(seq_names, seqs)):\n",
    "        for pos in range(len(s)):\n",
    "            if f\"{i}_pos{pos}\" == str(row):\n",
    "                wt = s[pos]\n",
    "                wt_dict[f\"{i}_pos{pos}\"] = wt\n",
    "                if (wt != '_'):\n",
    "                    wt_prob = output_df1.loc[row, wt]\n",
    "                else:\n",
    "                    wt_prob = '0'\n",
    "                wt_prob_d[f\"{i}_pos{pos}\"]= wt_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcae06e9-2345-4246-abc1-7bc37f1ae051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging and cleaning dataframes\n",
    "wt_df = pd.DataFrame.from_dict(wt_dict, orient='index', columns=['wt'])\n",
    "wt_df = wt_df.reset_index().rename(columns={'index': 'alias'})\n",
    "output_df1 = output_df1.reset_index().rename(columns={'index': 'alias'})\n",
    "output_df1 = pd.merge(output_df1, wt_df, on='alias', how='inner')\n",
    "wt_prob_df = pd.DataFrame.from_dict(wt_prob_d, orient='index', columns=['wt_prob'])\n",
    "wt_prob_df = wt_prob_df.reset_index().rename(columns={'index': 'alias'})\n",
    "output_df1 = pd.merge(output_df1, wt_prob_df, on='alias', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab51f81-a0b7-42ea-9e29-a67fe106b648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df24e857-54fb-4c03-960e-20550328c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating final dataframe\n",
    "import math\n",
    "e = math.e\n",
    "max_probs = output_df1.max(axis=1).to_list()\n",
    "max_prob_aas = output_df1.max_prob_aas.to_list()\n",
    "mAbs_pos = output_df1.alias.to_list()\n",
    "wt_list = output_df1.wt.to_list()\n",
    "wt_prob_l = output_df1.wt_prob.to_list()\n",
    "df_max2wt = pd.DataFrame({'mAbs_pos' : mAbs_pos, 'wt' : wt_list,'max_prob_aa' : max_prob_aas, 'wt_prob': wt_prob_l, 'max_prob' : max_probs})\n",
    "df_max2wt = df_max2wt[df_max2wt['wt'] != '_']\n",
    "df_max2wt['max/wt_ratio'] = (df_max2wt['max_prob'] / df_max2wt['wt_prob'])\n",
    "df_max2wt.to_csv(\"./TXG_mAbs_BALMMoE_maxmask2wt.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
